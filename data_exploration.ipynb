{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis of the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scripts.data_preprocessing import set_nan, convert_nan, standardize_data\n",
    "from scripts.proj1_helpers import load_csv_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading of the dataset and setting all -999 values to nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x, ids = load_csv_data(\"data/train.csv\")\n",
    "\n",
    "x = set_nan(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, as noted in the description of the features, some of them are left undefined in specific circumstances. We proceeded to check if the database corresponds to this description by veryfing that the occurences of undefined values are all grouped as they should be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nan(x):\n",
    "    \"\"\"\n",
    "    Counts nan values in each feature, then outputs ratio of nan/total values. \n",
    "    \n",
    "    :param x: input\n",
    "    :return: vector composed of ratios of nan for each feature\n",
    "    \"\"\"\n",
    "    x = set_nan(x)\n",
    "    truth_array = np.isnan(x)\n",
    "    return ((np.sum(truth_array, axis=0)) / x.shape[0])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nan_positions(x, features):\n",
    "    \"\"\"\n",
    "    Checks if the nans occur in all the selected features, outputs the percentage of values with nans \n",
    "    that are in all the chosen columns \n",
    "    \n",
    "    :param x: input\n",
    "    :return: value: percentage of nans present in all columns\n",
    "    \"\"\"\n",
    "\n",
    "    c = np.isnan(x[:, features])\n",
    "    check = np.sum(c, 1) == features.shape[0]\n",
    "\n",
    "    value = np.sum(check) / check.shape[0]\n",
    "    return value * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.2456  0.      0.      0.     70.9828 70.9828 70.9828  0.      0.\n",
      "  0.      0.      0.     70.9828  0.      0.      0.      0.      0.\n",
      "  0.      0.      0.      0.      0.     39.9652 39.9652 39.9652 70.9828\n",
      " 70.9828 70.9828  0.    ]\n",
      "70.9828\n",
      "39.9652\n",
      "10.4492\n"
     ]
    }
   ],
   "source": [
    "nan_ratios = count_nan(x) # vector of ratios of nan for each feature\n",
    "print(nan_ratios)\n",
    "features1 = np.array([4, 5, 6, 12, 26, 27, 28]) # features set undefined if the number of jets is <=1\n",
    "value1 = check_nan_positions(x, features1)\n",
    "print(value1)\n",
    "features2 = np.array([23, 24, 25]) # features set undefined if number of jets = 0 \n",
    "value2 = check_nan_positions(x, features2)\n",
    "print(value2)\n",
    "features3 = np.array([0, 23, 24, 25, 4, 5, 6, 12, 26, 27, 28]) \n",
    "# Counts how may datapoints have n_jets <=1 and, at the same time, \n",
    "# have an undefined theorical mass of the boson (feature 0)\n",
    "value3 = check_nan_positions(x, features3)\n",
    "print(value3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we verified how balanced the dataset is, and how balanced are the subsets characterized by a specific jet number, that have nans in the features outlined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_datapoints(y, x, features):\n",
    "    \"\"\"\n",
    "    Eliminates datapoints which have nans in all features of a specific set \n",
    "    \n",
    "    :param x: input datapoints\n",
    "    :param y: input event or background\n",
    "    :param features: features in which nans are present\n",
    "    :return: y,x\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    c = np.isnan(x[:, features])\n",
    "    check = np.sum(c, 1) == features.shape[0]\n",
    "    check = np.logical_not(check)\n",
    "    x = x[check, :]\n",
    "    y = y[check]\n",
    "    return y, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.342668\n"
     ]
    }
   ],
   "source": [
    "proportion_hits = np.sum(y[y == 1]) / y.shape[0] # Entire dataset\n",
    "print(proportion_hits)\n",
    "# Cutting of the datasets \n",
    "features4 = np.array([23, 24, 25, 4, 5, 6, 12, 26, 27, 28])\n",
    "y1, x1 = cut_datapoints(y, x, features1) # cutting jet numbers 0 and 1\n",
    "y2, x2 = cut_datapoints(y, x, features2) # cutting jet number 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of the portion of signal in the segments remaining after the cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4475276732420771\n",
      "0.40093412487423963\n"
     ]
    }
   ],
   "source": [
    "proportion_hits1 = np.sum(y1[y1 == 1]) / y1.shape[0]\n",
    "print(proportion_hits1) # 29% remaining with number of jets higher than 1\n",
    "proportion_hits2 = np.sum(y2[y2 == 1]) / y2.shape[0]\n",
    "print(proportion_hits2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there features that are a linear combination of other features? This function checks and outputs the indices of features that can be built by using a linear combination of others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_dependancy(x):\n",
    "    # define the matrix containing the inner products of the columns\n",
    "    inn_prod = x.T @ x\n",
    "    # define the matrix containing the products of the norms of the columns\n",
    "    arr_norm = np.linalg.norm(x, axis=0)[..., np.newaxis]\n",
    "    norm_prod = arr_norm @ arr_norm.T\n",
    "    # define the difference matrix\n",
    "    diff = inn_prod - norm_prod\n",
    "    # define indices where the difference is = 0\n",
    "    # the indices represents the linearly dependent columns\n",
    "    ind_dep = []\n",
    "    for i in range(diff.shape[0]):\n",
    "        for j in range(diff.shape[0]):\n",
    "            if i != j:\n",
    "                if np.abs(diff[i, j]) < 1E-1:\n",
    "                    id = np.array([i, j])\n",
    "                    ind_dep.append(id)\n",
    "    return ind_dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 6]\n",
      " [3 8]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_dependancy(x)\n",
    "o= np.array([[1,2],[3,6],[3,8]])\n",
    "print(o)\n",
    "linear_dependancy(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find further relationships between variables, the covariance matrix was computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance_matrix(x):\n",
    "    \"\"\"\n",
    "    Computes the covariance matrix computed with pearson's coefficient.\n",
    "    :param x: input \n",
    "    :return: covmat : covariance matrix\n",
    "    \"\"\"\n",
    "    xm = convert_nan(x, mode='mean')\n",
    "    xm = standardize_data(x) # Standardizes and substitutes nans with the mean of values of that feature\n",
    "    covmat = np.corrcoef(xm.T)\n",
    "    return covmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computed covariance values are then selected using a threshold with the two helper functions below, that output the correlated pairs of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance = covariance_matrix(x) \n",
    "\n",
    "def set_cov_inf(cov):\n",
    "    \"\"\"Sets the bottom half of the cov matrix as 0 to avoid repetition of related couples\"\"\"\n",
    "    cov_ = cov\n",
    "    for i in range(cov.shape[0]):\n",
    "        for j in range(cov.shape[1]):\n",
    "            if i >= j:\n",
    "                cov_[i, j] = 0\n",
    "    return cov_\n",
    "\n",
    "\n",
    "def corr_col(cov, threshold):\n",
    "    \"\"\"initializes an array filled with the columns to be eliminated\"\"\"\n",
    "    # threshold is the threshold correlation\n",
    "    cde = []\n",
    "    for i in range(cov.shape[0]):\n",
    "        for j in range(cov.shape[1]):\n",
    "            if abs(cov[i, j]) > threshold :\n",
    "                v = np.array([i, j])\n",
    "                cde.append(v)\n",
    "    return cde\n",
    "\n",
    "cov_ = set_cov_inf(covariance)\n",
    "col_el = corr_col(cov_, threshold=0.9)\n",
    "print(col_el, '\\n')\n",
    "\n",
    "cov_ = set_cov_inf(covariance)\n",
    "col_el = corr_col(cov_, threshold=0.8)\n",
    "print(col_el,'\\n')\n",
    "\n",
    "cov_ = set_cov_inf(covariance)\n",
    "col_el = corr_col(cov_, threshold=0.6)\n",
    "print(col_el,'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we drew the histograms of the distributions of the features, excluding nan values,\n",
    "overlapping signal and background distributions to highlight potential differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x, ids = load_csv_data(\"data/train.csv\")\n",
    "\n",
    "x = set_nan(x)\n",
    "\n",
    "figure1 = plt.figure(1)\n",
    "for i in range(30):\n",
    "    plt.subplot(5, 6, i + 1)\n",
    "    k = x[:, i]\n",
    "    kt = k[y == 1]\n",
    "    kf = k[y == -1]\n",
    "\n",
    "    plt.hist(kt[~np.isnan(kt)], bins='auto', alpha=0.5, facecolor='b')\n",
    "    plt.hist(kf[~np.isnan(kf)], bins='auto', alpha=0.5, facecolor='r')\n",
    "    plt.title(f'feature : {i}')\n",
    "    plt.axis('tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems features 15, 18, 20, 25 and 28 do not add information, as the distribution of hits and misses are very similar and constant. To make sure that the ratio between hits and misses does not change depending on the value of the feature, we drew lineplots of the ratios.\n",
    "if this ratio is constant then the feature does not have predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure2 = plt.figure(2)\n",
    "L = 50  # number of bins\n",
    "ratio = np.zeros(L)\n",
    "for i in range(30):\n",
    "    plt.subplot(5, 6, i + 1)\n",
    "    k = x[:, i]\n",
    "    kt = k[y == 1]\n",
    "    kf = k[y == -1]\n",
    "    kt = kt[~np.isnan(kt)]\n",
    "    kf = kf[~np.isnan(kf)]\n",
    "    kthist = np.histogram(kt, bins=L, range=(np.min(k[~np.isnan(k)]), np.max(k[~np.isnan(k)])))\n",
    "    kfhist = np.histogram(kf, bins=L, range=(np.min(k[~np.isnan(k)]), np.max(k[~np.isnan(k)])))\n",
    "    for j in range(L):\n",
    "        if kfhist[0][j] == 0 or kthist[0][j] == 0:\n",
    "            ratio[j] = 0\n",
    "        else:\n",
    "            ratio[j] = kthist[0][j] / kfhist[0][j]\n",
    "    binz = kthist[1][0:L]\n",
    "    plt.plot(binz, ratio)\n",
    "    plt.title(f'feature : {i}')\n",
    "    plt.ylim(0, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
